{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: AWS S3 & Sourcing Datasets\n",
    "Republish this open dataset in Amazon S3 and share with us a link.\n",
    "You may run into 403 Forbidden errors as you test accessing this data. There is a way to comply with the BLS data access policies and re-gain access to fetch this data programatically - we have included some hints as to how to do this at the bottom of this README in the Q/A section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required sub-steps to accomplisht this:\n",
    "1. Set up S3 bucket environmnet\n",
    "2. Be able to read and publish into S3 env. \n",
    "3. troubleshoot error\n",
    "\n",
    "- Key notes: This is DataLake design. Create a landing-zone where data will be uploaded and parsed under upload date. The goal is just to have a starting point to being bringing in data into s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = os.getenv('AWS_ACCESS_KEY')\n",
    "secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-02-ep-website\n",
      "aws-emr-resources-386175835981-us-east-2\n",
      "aws-logs-386175835981-us-east-2\n",
      "bigbatbucket\n",
      "canvas-bucket-iris-4123\n",
      "dbdatalocation\n",
      "ed-exp-cost-and-usage\n",
      "eddysfistbuck\n",
      "edwardplatagschoolcap\n",
      "eplatacapstonedata\n",
      "eplatacapstoneipynb\n",
      "qep-sports-betting-bucket\n",
      "rearc-datalake-bucket\n",
      "redditdatacollectionwemeta\n",
      "sagemaker-soln-ddf-js-2ruwg4-386175835981-us-east-1\n",
      "sagemaker-soln-ddf-js-2seloa-386175835981-us-east-1\n",
      "sagemaker-soln-ddf-js-2sf3s6-386175835981-us-east-1\n",
      "sagemaker-soln-ddf-js-44xdya-386175835981-us-east-1\n",
      "sagemaker-soln-documents-js-4htc2a-us-east-1-386175835981\n",
      "sagemaker-studio-386175835981-l4ayz3cscdq\n",
      "sagemaker-studio-386175835981-l9tzph12na\n",
      "sagemaker-studio-386175835981-zzqac2052o\n",
      "sagemaker-us-east-2-386175835981\n",
      "someonesbucket\n",
      "ss-discord-group-minecraft-bucket\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.list_buckets()\n",
    "\n",
    "if 'Buckets' in response:\n",
    "    buckets = response['Buckets']\n",
    "    for bucket in buckets:\n",
    "        print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have access to the s3 bucekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: AWS S3 & Sourcing Datasets\n",
    "1. Republish [this open dataset](https://download.bls.gov/pub/time.series/pr/) in Amazon S3 and share with us a link.\n",
    "    - You may run into 403 Forbidden errors as you test accessing this data. There is a way to comply with the BLS data access policies and re-gain access to fetch this data programatically - we have included some hints as to how to do this at the bottom of this README in the Q/A section.\n",
    "2. Script this process so the files in the S3 bucket are kept in sync with the source when data on the website is updated, added, or deleted.\n",
    "    - Don't rely on hard coded names - the script should be able to handle added or removed files.\n",
    "    - Ensure the script doesn't upload the same file more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import boto3\n",
    "\n",
    "# AWS credentials\n",
    "access_key = os.getenv('AWS_ACCESS_KEY')\n",
    "secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# S3 bucket and landing zone details\n",
    "bucket_name = 'rearc-datalake-bucket'\n",
    "landing_zone_prefix = 'landing-zone/'\n",
    "\n",
    "# Create an S3 client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")\n",
    "\n",
    "# Check if the landing zone exists, create it if it doesn't\n",
    "response = s3_client.list_objects_v2(\n",
    "    Bucket=bucket_name,\n",
    "    Prefix=landing_zone_prefix\n",
    ")\n",
    "\n",
    "if 'Contents' not in response:\n",
    "    s3_client.put_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=landing_zone_prefix\n",
    "    )\n",
    "    print(f\"Landing zone '{landing_zone_prefix}' created in bucket '{bucket_name}'.\")\n",
    "\n",
    "# Fetch data from the provided link and upload to S3 landing zone\n",
    "url = 'https://download.bls.gov/pub/time.series/pr/'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    files = response.text.split('\\n')\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_name = file.split('/')[-1]\n",
    "            s3_client.put_object(\n",
    "                Bucket=bucket_name,\n",
    "                Key=f\"{landing_zone_prefix}{file_name}\",\n",
    "                Body=requests.get(f\"{url}{file}\").content\n",
    "            )\n",
    "            print(f\"Uploaded '{file_name}' to landing zone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
